---
title: "Imputing missing data and defining a new Jaccard-like distance"
author: "Laura Symul"
date: "12/10/2018"
output: html_document
---



```{r imputing_missing_data_and_new_jaccard_like_distance setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```



```{r imputing_missing_data_and_new_jaccard_like_distance librairies and stuff, include = FALSE, eval = TRUE}
rm(list=ls())
source("00_variables.R")
source("00_libraries.R")
source("00_functions.R")
source("00_setup.R")
```


## IMPUTING MISSING DATA and DEFINING a new Jaccard-like DISTANCE

### Exploring existing distances on fake data

```{r imputing_missing_data_and_new_jaccard_like_distance loading fake data}

df = read.csv("fake_data_for_distance_exploration.csv", header = FALSE)
M = as.matrix(df)

format.obs.matrix = function(M){
  df = as.data.frame(M)
  colnames(df) = 1:ncol(df)
  df$cycle_id = paste0("c",1:nrow(df))
  #df = reshape(df, idvar = "cycle_id",varying = list(c(1:ncol(M))), direction = "long") 
  df = suppressMessages(melt(df))
  #colnames(df)[which(colnames(df) == "time")] = "day" 
  colnames(df)[which(colnames(df) == "variable")] = "day" 
  df$logs = factor(df$value, levels = sort(unique(df$value)))
  df$cycle_id = factor(df$cycle_id, levels = sort(unique(df$cycle_id),decreasing = TRUE))
  return(df)
}

df = format.obs.matrix(M)

g_df = ggplot(df, aes(x = day, y = cycle_id, fill = logs)) + geom_tile(colour = "white") + scale_fill_manual(values = c("white","gray","deeppink")) + guides(fill = FALSE)+ ggtitle("obs")
#g_df

```


```{r imputing_missing_data_and_new_jaccard_like_distance comparing existing distances, fig.height=3, fig.width=12}

jaccard = function(M){
  margin = 1
  N = nrow(M)
  J = matrix(0, nrow = N, ncol =N)
  for(i in 1:(N-1)){
    #cat(i,"\n")
    for(j in min((i+1),N):N){
      #cat("\t",j,"\n")
      J[i,j] = 1 - sum((M[i,] == 1) & (M[j,] == 1))/sum((M[i,] == 1) | (M[j,] == 1))
      J[j,i] = J[i,j]
    }
  }
  return(J)
}


format.dist.mat = function(dist_mat){
  dist_mat[lower.tri(dist_mat)] = 0
  df_dist = as.data.frame(dist_mat)
  colnames(df_dist) = paste0("c",1:nrow(df_dist))
  df_dist$cycle_id = paste0("c",1:nrow(df_dist))
  df_dist = suppressMessages(melt(df_dist))
  colnames(df_dist)[which(colnames(df_dist) == "variable")] = "cycle_id_y"
  df_dist$cycle_id = factor(df_dist$cycle_id, levels = sort(unique(df_dist$cycle_id),decreasing = FALSE))
  df_dist$cycle_id_y = factor(df_dist$cycle_id_y, levels = sort(unique(df_dist$cycle_id_y),decreasing = TRUE))
  return(df_dist)
}


euclidian.dist = format.dist.mat(as.matrix(dist(M, method = "euclidian")))
binary.dist = format.dist.mat(as.matrix(dist(M, method = "binary")))
jaccard.dist = format.dist.mat(jaccard(M))

N_cycles = length(unique(df$cycle_id))

g_eucl = ggplot(euclidian.dist, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("euclidian") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)
g_binary = ggplot(binary.dist, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("binary") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)
g_jaccard = ggplot(jaccard.dist, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("jaccard") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)

grid.arrange(g_df, g_eucl, g_binary, g_jaccard, ncol=4, widths = c(2,1,1,1) )

rm(euclidian.dist, binary.dist, jaccard.dist, N_cycles)


```

Jaccard distance (https://en.wikipedia.org/wiki/Jaccard_index) is probably doing best what we want to do.
The problem is that a missing data in the middle of a logged sequence should not be treated the same as a missing data at the beginning or the end of a sequence.


### Imputing data: principles.

For any $i$ that is in a "missing data" position (i.e. n_logs = 0) in a sequence of **max 3 missing days in a row** and that is **not at the beginning or the end** of the cycle_m

$x_i = interpolation_i(X_L - X_N) * F_i$

where $x_i$ is the imputed value at position $i$,
$X_L$ is the TB value on the **Last** day where anything got logged (can be 1 or 0)
$X_N$ is the TB value on the **Next** day where anything got logged (can be 1 or 0)
$F_i$ is a factor that must reflect

* the uncertainty of imputing data: we actually DO NOT know what happened 

* the total number of missing day in a row: if we are missing more days, the uncertainty increases. 

* the position in the missing day sequence: we have more uncertainties in the middle than at the edges of a missing day sequence.

We have the conditions:

$ F_i < 1 $

and if $N_S1 > N_S2$ where $N_S1$ (resp $N_S2$) = length of missing days in a row in sequence 1 (resp 2), then $F_i1 < F_i2$ 

and $ F_i < F_j $ if $i$ is more on the middle than $j$


$F_i$ of the shape of an hyperbolic cosine could be a good option that respect these conditions.

[https://en.wikipedia.org/wiki/Catenary](https://en.wikipedia.org/wiki/Catenary)


Remaining question: should we also take into account the actual number of logs at the edges of a missing sequence?

```{r imputing_missing_data_and_new_jaccard_like_distance imputing data function}

ncosh = function(x, factor = 1){
  y = cosh(seq(-(x-1)/2,(x-1)/2)) / factor
  return(y/sum(y))
}

ncosh.dict = data.frame(sac.value = c(2,3,4,5), Factor.value = c(1, 0.5, 0.38, 0.24))


impute = function(obs = c(-1,-1,-1,0,1,-1,0,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,1,-1,0)){
  #cat(obs,"\n")
  obs = as.vector(obs)
  new_obs = obs
  if(any(obs == -1)){
    # get the indices of missing data
    j = which(new_obs == -1)
    #removing leading sequences of missing data
    j = j[!(j == (1:length(j)))]
    #removing ending sequences of missing data
    j = j[!(j == (length(obs)-length(j)+1):length(obs))]
    #removing sequence longer than 3
    x = c(0,diff(j)) == 1
    ac = ave(x, cumsum(x == 0), FUN = cumsum)
    y = (1:length(j)) - ac
    irm = which(y %in% y[ac>=3])
    if(length(irm)>0){j = j[-irm]}
    
    if(length(j)>0){
      # obs_approx (interpolation of values)
      i = 1:length(obs)
      obs_approx = approx(x = i[-j],y = obs[-j],xout = i)$y
      
      # Factor
      x = 1*(obs<0)
      ac = ave(x, cumsum(x == 0), FUN = cumsum)
      rac = rev(ave(rev(x), cumsum(rev(x) == 0), FUN = cumsum))
      sac = ac+rac+((ac == 2)&(rac == 2))
      Factor = x * ncosh.dict$Factor.value[match(sac, ncosh.dict$sac.value)]
      
      new_obs[j] = obs_approx[j] * Factor[j] * 0.75
      #plot(obs, type = "b")
      #points(new_obs_tmp, type = "b", col = "blue")
      #points(new_obs, type = "b", col = "tomato")
    }
  }
  return(t(new_obs))
}

```


```{r imputing_missing_data_and_new_jaccard_like_distance imputing examples}

new_M = t(apply(M, 1, impute))

new_df = format.obs.matrix(new_M)


g_new_df = ggplot(new_df, aes(x = day, y = cycle_id, fill = value)) + geom_tile(colour = "white") +  scale_fill_gradient2(low = "white",mid = "gray", high = "deeppink") + ggtitle("obs with imputed missing data")


g_df
g_new_df
```


```{r imputing_missing_data_and_new_jaccard_like_distance new jaccard distance}

new_jaccard_2_vec_no_w = function(x, y, r = 0.8){
  x1 = pmax(x,0); y1 = pmax(y, 0)
  I1 = sum(x1 * y1)/(sum(x1 + y1)-sum(x1 * y1))
  x0 = (x>=0) ; y0 = (y>=0)
  I0 = sum(x0 & y0)/(sum(x0 | y0))
  D = 1 - r*I1 - (1-r)*I0
  return(D)
}

new_jaccard_no_w = function(M, r = 0.8){
  margin = 1
  N = nrow(M)
  J = matrix(0, nrow = N, ncol =N)
  for(i in 1:(N-1)){
    #cat(i,"\n")
    for(j in min((i+1),N):N){
      #cat("\t",j,"\n")
      d = new_jaccard_2_vec_no_w(x = M[i,], y = M[j,], r = r)
      J[i,j] = d
      J[j,i] = d
    }
  }
  return(J)
}


new_jaccard_2_vec_no_w_minmax = function(x, y, r = 0.8, w = NA){
  x1 = pmax(x,0); y1 = pmax(y, 0)
  I1 = sum(pmin(x1,y1))/sum(pmax(x1,y1))
  x0 = (x>=0) ; y0 = (y>=0)
  I0 = sum(x0 & y0)/(sum(x0 | y0))
  D = 1 - r*I1 - (1-r)*I0
  return(D)
}

new_jaccard_no_w_minmax = function(M, r = 0.8){
  margin = 1
  N = nrow(M)
  J = matrix(0, nrow = N, ncol =N)
  for(i in 1:(N-1)){
    #cat(i,"\n")
    for(j in min((i+1),N):N){
      #cat("\t",j,"\n")
      d = new_jaccard_2_vec_no_w_minmax(x = M[i,], y = M[j,], r = r)
      J[i,j] = d
      J[j,i] = d
    }
  }
  return(J)
}


```


```{r imputing_missing_data_and_new_jaccard_like_distance comparison new jaccard distance, fig.width=14, fig.height=3}

r = 0.6

new_jaccard_no_w.dist = format.dist.mat(new_jaccard_no_w(M, r = r))


new_jaccard_no_w.dist.on_imputed_data = format.dist.mat(new_jaccard_no_w(new_M, r = r))

new_jaccard_no_w_minmax.dist.on_imputed_data = format.dist.mat(new_jaccard_no_w_minmax(new_M, r = r))


N_cycles = length(unique(df$cycle_id))

g_new_jaccard_no_w = ggplot(new_jaccard_no_w.dist, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("new jaccard") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)

g_new_jaccard_no_w_imputed = ggplot(new_jaccard_no_w.dist.on_imputed_data, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("new jacc. w/ imputed") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)

g_new_jaccard_no_w_minmax_imputed = ggplot(new_jaccard_no_w_minmax.dist.on_imputed_data, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("new jacc. w/ imputed") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)


grid.arrange(g_df, g_jaccard, g_new_jaccard_no_w, g_new_jaccard_no_w_imputed, g_new_df + guides(fill = FALSE),  ncol=5, widths = c(2,1,1,1,2) )


```


```{r imputing_missing_data_and_new_jaccard_like_distance testing PAM with new jaccard and imputed}

new_jaccard_dist_matrix = new_jaccard_no_w(new_M, r = r)

pam(x = new_jaccard_dist_matrix, k = 3, diss = TRUE, cluster.only = TRUE)

kmeans(new_M, centers = 3, nstart = 20)$cluster

kmeans(pmax(M,0), centers = 3, nstart = 20)$cluster

```


It works and the PAM on the new jaccard distance with imputed data is giving me what I want.



We could also introduce a weight on the different days as 

```{r imputing_missing_data_and_new_jaccard_like_distance new weighted jaccard distance}

new_jaccard_vecs = function(x, y, r = 0.8, w = NA){
  if(any(is.na(w))){w = 0*x+1}
  if(any((w>1)|(w<0))){stop("w must be between 0 and 1\n")}
  x1 = w*pmax(x,0); y1 = w*pmax(y, 0)
  I1 = sum(pmin(x1,y1))/sum(pmax(x1,y1))
  x0 = w*(x>=0) ; y0 = w*(y>=0)
  I0 = sum(pmin(x0,y0))/sum(pmax(x0,y0))
  D = 1 - r*I1 - (1-r)*I0
  return(D)
}

new_jaccard = function(M, r = 0.8, w = NA){
  margin = 1
  N = nrow(M)
  J = matrix(0, nrow = N, ncol =N)
  for(i in 1:(N-1)){
    #cat(i,"\n")
    for(j in min((i+1),N):N){
      #cat("\t",j,"\n")
      d = new_jaccard_vecs(x = M[i,], y = M[j,], r = r, w = w)
      J[i,j] = d
      J[j,i] = d
    }
  }
  return(J)
}
```




```{r imputing_missing_data_and_new_jaccard_like_distance comparison new weigthed jaccard distance, fig.width=14, fig.height=3}

r = 0.6

w = c(0.1,0.2,0.4,0.7,0.9,1,1,1,0.9,0.7,0.5)

plot(w, type = "b")

new_jaccard.dist = format.dist.mat(new_jaccard(new_M, r = r, w = w))

N_cycles = length(unique(df$cycle_id))

g_new_jaccard = ggplot(new_jaccard.dist, aes(x = cycle_id, y = cycle_id_y, fill = value))+ ggtitle("weighted J with imp. data") + geom_tile(colour = "gray80") + scale_fill_gradient(low = "white", high = "tomato") + geom_abline(slope = -1, intercept = N_cycles+1, col = "gray") + guides(fill = FALSE)

grid.arrange(g_df, g_jaccard, g_new_jaccard_no_w_imputed, g_new_jaccard, g_new_df + guides(fill = FALSE),  ncol=5, widths = c(2,1,1,1,2) )


```





# This distance is better than euclidian of course BUT

- I think for the tracking behavior, it makes more sense to use a binary distance - otherwise, it artificially put closer together users with high-tracking frequency cycles.

- For the symptoms, the jaccard distance is great, but we need, on top of the data imputation, to add a little bit of delay between the sequences. Otherwise, users with few symptoms (only one day or 2) around their period can be seen as completely different while they are quite similar.



```{r TB distance}


cppFunction(
'NumericMatrix TB_distance_Rccp(NumericMatrix M_symptoms, NumericMatrix M_any_log , double r) {
  int N = M_symptoms.nrow();
  NumericMatrix J(N,N);
  for(int i = 0; i < (N-1); i++){
    for(int j = i+1; j < (N); j++){

      double Tracking_binary = sum(M_any_log(i,_) == M_any_log(j,_));
      double vector_size = (M_any_log(i,_).size());
      double Tracking_index = Tracking_binary/vector_size;
 
      NumericVector Symptom_overlap = pmin(M_symptoms(i,_),M_symptoms(j,_));
      NumericVector Symptom_union = pmax(M_symptoms(i,_),M_symptoms(j,_));
      double Symptom_index;
      if(sum(Symptom_union) == 0) {Symptom_index = Tracking_index/2;} 
      else{ Symptom_index = sum(Symptom_overlap) / sum(Symptom_union); }

      double d  = 1 - r*Symptom_index - (1-r)*Tracking_index; 

      J(i,j) = d;
      J(j,i) = d;
    }
  }
  return J;
}'
)


TB_distance = function(M, r = 0.75, w = NA){
  if(any(is.na(w))){w = rep(1,ncol(M))}
  if(any((w>1)|(w<0))){stop("w must be between 0 and 1\n")}
  if(length(w) != ncol(M)){stop("w must be NA or the same length as the number of columns of M\n")}
  M = as.matrix(M)
  
    
  M_any_log = 1*(M>=0);
  M_any_log = sweep(M_any_log,MARGIN=2,w,`*`)
  
  M_symptoms = M;
  M_symptoms[M_symptoms<0] = 0
  M_symptoms = sweep(M_symptoms,MARGIN=2,w,`*`)

  
  J = TB_distance_Rccp(M_symptoms, M_any_log, r)
  return(J)
}

```

```{r TB_distance test}

x1 = c(-1,-1,-1,0,0,0)
x2 = c(-1,-1,-1,1,0,0)
x3 = c(-1,-1,-1,1,1,0)
x4 = c(0,0,0,-1,-1,-1)
x5 = c(0,0,0,1,-1,-1)


M = matrix(c(x1,x2,x3,x4,x5),nrow = 5, byrow = TRUE)
M 

round(TB_distance(M), digits = 3)





```







```{r testing the TB distance + compare to the old one, fig.height=10}

output_folder = paste0(IO$tmp_Rdata,"avg_dist_per_user/")
load(file = paste0(output_folder, "d_1.Rdata"), verbose = TRUE)
load(file = paste0(IO$tmp_Rdata, "avg_dist_per_user.Rdata"), verbose = TRUE)


#d$median_d = avg_dist_per_user$median_d[match(d$user_id, avg_dist_per_user$user_id)]

avg_dist_per_user = avg_dist_per_user[!is.na(match(avg_dist_per_user$user_id,d$user_id)),]
o1 = order(avg_dist_per_user$median_d)
o2 = order(avg_dist_per_user$median_d, decreasing = TRUE)

#user_ids = c(as.character(avg_dist_per_user$user_id[o1[1:3]]), as.character(avg_dist_per_user$user_id[o2[1:3]]))
user_ids = sort(sample(unique(d$user_id),5))

d = d[d$user_id %in% user_ids,]

for(u in user_ids){
  cat(u,"\n")
  sub_d = d[d$user_id == u,]
  
  cat("\t TB_distance\n")
  
  TB_dist = TB_distance(M = sub_d[,-c(1,2)], r = par$r, w = par$w)
  TB_dist_val = TB_dist[upper.tri(TB_dist)]
  
  cat("\t\t",mean(TB_dist_val),"\n")
  cat("\t\t",median(TB_dist_val),"\n")
  cat("\t\t",sd(TB_dist_val),"\n")
  
  cat("\t new_jaccard\n")
  
  dist = new_jaccard(M = sub_d[,-c(1,2)], r = par$r, w = par$w)
  dist_val = dist[upper.tri(dist)]
  
  cat("\t\t",mean(dist_val),"\n")
  cat("\t\t",median(dist_val),"\n")
  cat("\t\t",sd(dist_val),"\n")
}

d = melt(d)
d$cycleday_m_D = as.numeric(gsub("\\.","-",gsub("n\\.","",d$variable)))
d$cycle_nb_m = unlist(strsplit(as.character(d$cycle_id_m), "_"))[(1:nrow(d))*2]
d$tender_breasts = d$value
d$user_id = factor(as.character(d$user_id), levels = user_ids)

g = ggplot_imputed_TB(sel_d = d, facet_grid = "user_id", cycle_id = FALSE)
g



```





```{r TB distance with smooth}

TB_distance = function(M, r = 0.75, w = NA, smooth = TRUE, filter = c(1/4,1/2,1/4)){
  if(any(is.na(w))){w = rep(1,ncol(M))}
  if(any((w>1)|(w<0))){stop("w must be between 0 and 1\n")}
  if(length(w) != ncol(M)){stop("w must be NA or the same length as the number of columns of M\n")}
  M = as.matrix(M)
  
    
  M_any_log = 1*(M>=0);
  M_any_log = sweep(M_any_log,MARGIN=2,w,`*`)
  
  M_symptoms = M;
  M_symptoms[M_symptoms<0] = 0
  M_symptoms = sweep(M_symptoms,MARGIN=2,w,`*`)
  
  if(smooth){
    M_tmp = cbind(M_symptoms[,1],M_symptoms,M_symptoms[,ncol(M_symptoms)])
    M_tmp = t(apply(M_tmp, MARGIN = 1, FUN = function(x, f) { y = stats::filter(x, filter = f); y = y[!is.na(y)]; return(y)}, filter))
    M_symptoms = M_tmp
  }
  
  J = TB_distance_Rccp(M_symptoms, M_any_log, r)
  return(J)
}

```



```{r smooth test}

x1 = c(-1,-1,-1,0,1,0)
x2 = c(-1,-1,-1,1,0,0)
x3 = c(-1,-1,-1,1,1,0)
x4 = c(0,0,0,-1,-1,-1)
x5 = c(0,0,0,1,-1,-1)


M = matrix(c(x1,x2,x3,x4,x5),nrow = 5, byrow = TRUE)
M 

X1 = round(TB_distance(M, smooth = FALSE), digits = 3)

X2 =round(TB_distance(M), digits = 3)

X1
X2

X1 == X2



```










