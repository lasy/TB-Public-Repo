# re-order clusters by avg silh score.
o = order(clusters_clara$silinfo$clus.avg.widths, decreasing = TRUE)
cl_table = data.frame(cl_i = o, cl_num = 1:length(o),cl = paste0("cl",1:length(o)))
cl_table = cl_table[order(cl_table$cl_i),]
cycles_m$cluster = cl_table$cl[clusters_clara$clustering[match(cycles_m$cycle_id_m, d_wide$cycle_id_m)]]
cycles_m$cluster_num = cl_table$cl_num[clusters_clara$clustering[match(cycles_m$cycle_id_m, d_wide$cycle_id_m)]]
d$cluster = cl_table$cl[clusters_clara$clustering[match(d$cycle_id_m, d_wide$cycle_id_m)]]
d$cluster_num = cl_table$cl_num[clusters_clara$clustering[match(d$cycle_id_m, d_wide$cycle_id_m)]]
# silhouette info
silh = as.data.frame(clusters_clara$silinfo$widths)
silh$x = 1:nrow(silh)
silh$rows = as.numeric(rownames(silh))
silh$cluster_i = silh$cluster
silh$cluster = cl_table$cl[silh$cluster_i]
silh$cluster_num = cl_table$cl_num[silh$cluster_i]
silh$neighbor_i = silh$neighbor
silh$neighbor = cl_table$cl[silh$neighbor_i]
silh$neighbor_num = cl_table$cl_num[silh$neighbor_i]
silh = silh[order(silh$cluster, silh$x),]
silh$x = 1:nrow(silh)
silh = silh[,c("x","cluster","neighbor","sil_width","rows", "cluster_num","neighbor")]
rownames(d) = 1:nrow(d)
d = d[,c("user_id","cycle_id_m","cycle_nb_m","cycleday_m_D","tender_breasts","cluster","cluster_num")]
#### plots
# showing some random examples with d
set.seed(10)
random_cycle_ids = cycle_ids[sample(1:length(cycle_ids),50)]
d_subset = d[d$cycle_id_m %in% random_cycle_ids,]
# ordered colored dots
d_subset = d_subset[order(d_subset$cluster_num),]
d_subset$cycle_id_m = factor(d_subset$cycle_id_m, levels = unique(d_subset$cycle_id_m))
print(ggplot_imputed_TB(d_subset, facet_grid = NULL)+scale_size(range = c(2,2)))
rm(random_cycle_ids, d_subset)
# show the samples chosen by clara FOR SILHOUETTE
m = match(silh$rows, rownames(d_wide))
cycle_ids_silh = as.character(d_wide$cycle_id_m[m])
m = which(!is.na(match( d$cycle_id_m, cycle_ids_silh)))
d_subset = d[m,]
d_subset = d_subset[order(d_subset$cluster_num),]
d_subset$cycle_id_m = factor(d_subset$cycle_id_m, levels = rev(cycle_ids_silh))
save(d_subset, file = paste0(IO$out_Rdata, "representative_cycles_clusters.Rdata"))
g_samples = ggplot_imputed_TB(d_subset, facet_grid = NULL)+scale_size(range = c(2,2)) + ggtitle(paste0("r = ",r))
rm(m, cycle_ids_silh, d_subset)
g_silh = ggplot(silh, aes(fill = factor(cluster),x = factor(x, levels =rev(x)), y = sil_width)) + coord_flip()+
geom_bar(stat = "identity")+
geom_point(aes( col = factor(neighbor),y = pmax(0,sil_width) + 0.025), size = 3)+
#ylim(c(-1,1))+
geom_hline(yintercept = clusters_clara$silinfo$avg.width, linetype = 2)+
ggtitle(paste0("avg. silh score = ",round(clusters_clara$silinfo$avg.width,digits = 3)))+
guides(fill = FALSE, color = FALSE)+
xlab("")+ylab("silh width")+ scale_x_discrete(position = "top")
mds_eig = cmdscale(d = clusters_clara$diss, k = 10, eig = TRUE)
mds = data.frame(mds_eig$points)
colnames(mds) = c(paste0("d",1:10))
mds$cluster_num = as.factor(cl_table$cl_num[clusters_clara$clustering[match(rownames(mds), names(clusters_clara$clustering))]])
m = match( silh$rows, rownames(mds))
mds = mds[m,]
mds$num = 1:nrow(mds)
save(mds, file = paste0(IO$out_Rdata, "mds_representative_samples.Rdata"))
save(mds_eig, file = paste0(IO$out_Rdata, "mds_eig.Rdata"))
g_mds = ggplot(mds, aes(x = d1, y = d2, col = cluster_num)) + coord_fixed()+
geom_point(size = 4, alpha = 0.5) +
geom_text(label = 1:nrow(mds))+
guides(color = FALSE)+ggtitle("MDS")+xlab("")+ylab("")
grid.arrange(g_samples, g_silh, g_mds, nrow = 1, widths = c(2,1,2.2))
rm(g_samples, g_silh, g_mds)
rm(mds, m)
# symptom profiles for the clusters
d$tb_binary = (d$tender_breasts==1)*1
agg = aggregate(tb_binary ~ cycleday_m_D + cluster_num, d, sum)
#print(ggplot(agg, aes(x = cycleday_m_D, y = tb_binary, col = factor(cluster_num))) + geom_line() + facet_grid(cluster_num ~.))
agg2 = aggregate(cycle_id_m ~ cluster_num, d, lu)
colnames(agg2)[length(colnames(agg2))] = "n_cycles"
agg  = merge(agg, agg2, all = TRUE)
agg$fraction_of_cycles = agg$tb_binary/agg$n_cycles
# average tracking behavior profiles
agg2 = aggregate(cycle_id_m ~ cycleday_m_D + cluster_num, d[d$tender_breasts>=0,],lu)
colnames(agg2)[length(colnames(agg2))] = "n_cycles_with_logs"
agg  = merge(agg, agg2, all = TRUE)
agg$fraction_of_cycles_with_logs = agg$n_cycles_with_logs/agg$n_cycles
g_symptom_profiles = ggplot(agg, aes(x = cycleday_m_D, y = fraction_of_cycles, col = factor(cluster_num))) + geom_point(size = 0.6) + geom_line()
g_tracking_profiles = ggplot(agg, aes(x = cycleday_m_D, y = fraction_of_cycles_with_logs, col = factor(cluster_num))) + geom_point(size = 0.6) + geom_line() + ylim(c(0,1))
grid.arrange(g_symptom_profiles, g_tracking_profiles)
save(agg, file = paste0(IO$out_Rdata, "breast_tenderness_and_tracking_profiles_per_clusters_clara.Rdata"))
rm(agg, agg2, g_symptom_profiles, g_tracking_profiles)
# and showing the medoids
medoids = as.data.frame(clusters_clara$medoids)
colnames(medoids) = paste0("tender_breasts.",(-18:7)+18)
medoids$cluster_num = cl_table$cl_num[1:n_center]
medoids = reshape(medoids, idvar = "cluster_num", varying = 1:(ncol(medoids)-1), direction = "long")
medoids$cycleday_m_D = medoids$time-18
print(ggplot(medoids, aes(x = cycleday_m_D, y = tender_breasts, col =  factor(cluster_num)))+geom_hline(yintercept = 0, col = "gray") + geom_line(size = 1.5)+ facet_grid(cluster_num ~.))
print(ggplot(medoids, aes(x = cycleday_m_D, y = tender_breasts, col =  factor(cluster_num)))+geom_hline(yintercept = 0, col = "gray") + geom_line(size = 1.5, alpha = 0.5))
# plus showing the number of cycles in each cluster
print(ggplot(data.frame(as.data.frame(clusters_clara$clusinfo),cluster_num = cl_table$cl_num), aes(x = cluster_num, y = size, fill = factor(cluster_num))) + geom_bar(stat = "identity")+ guides(fill = FALSE))
par$run_optimal_nb_of_cluster = FALSE
source("Scripts/00_setup.R")
load(paste0(IO$output_data, "users.Rdata"), verbose = TRUE)
output_folder = paste0(IO$tmp_data,"avg_dist_per_user/")
dir.create(output_folder)
input_folder = paste0(IO$output_data,"days/")
days_files = list.files(input_folder)
days_files = days_files
N = length(days_files)
n = 1
N
output_file = paste0(output_folder, "d_",n,".Rdata")
if(!file.exists(output_file)){
load(paste0(input_folder,days_files[n]), verbose = TRUE)
#impute and transform all cycles to wide format, including cycles without TB logs
user_ids = unique(days$user_id[days$type == "tender_breasts"])
days = days[days$user_id %in% user_ids,]
d = reshape_and_impute(days)
save(d, file = output_file)
}
registerDoParallel(par$n_cores)
tic()
foreach(n = 1:N)%dopar%{
output_file = paste0(output_folder, "d_",n,".Rdata")
if(!file.exists(output_file)){
load(paste0(input_folder,days_files[n]), verbose = TRUE)
#impute and transform all cycles to wide format, including cycles without TB logs
user_ids = unique(days$user_id[days$type == "tender_breasts"])
days = days[days$user_id %in% user_ids,]
d = reshape_and_impute(days)
save(d, file = output_file)
}
}
toc()
stopImplicitCluster()
source("Scripts/00_functions_distance.R")
registerDoParallel(par$n_cores)
tic()
foreach(n = 1:N)%dopar%{
output_file = paste0(output_folder,"users_with_avg_distance_",n,".Rdata")
if(!file.exists(output_file)){
load(file = paste0(output_folder, "d_",n,".Rdata"), verbose = TRUE)
# compute average distance
users_with_avg_distance = foreach(u = unique(d$user_id), .combine = rbind) %do% {
dist_summary = compute_average_distance(d = d[d$user_id == u,])
return(data.frame(user_id = u, avg_d = dist_summary$mean, median_d = dist_summary$median, sd_d = dist_summary$sd, file = n))
}
save(users_with_avg_distance, file = output_file)
}
}
toc()
stopImplicitCluster()
registerDoParallel(par$n_cores)
tic()
avg_dist_per_user = foreach(n = 1:N,.combine = rbind)%dopar%{
load(file = paste0(output_folder,"users_with_avg_distance_",n,".Rdata"), verbose = TRUE)
return(users_with_avg_distance)
}
toc()
stopImplicitCluster()
save(avg_dist_per_user, file = paste0(IO$tmp_data,"avg_dist_per_user.Rdata"))
load(file = paste0(output_folder, "d_1.Rdata"), verbose = TRUE)
load(paste0(IO$tmp_data,"avg_dist_per_user.Rdata"), verbose = TRUE)
avg_dist_per_user = avg_dist_per_user[which(avg_dist_per_user$user_id %in% unique(d$user_id)),]
o  = order(avg_dist_per_user$median_d)
user_ids =  as.character(avg_dist_per_user$user_id[o[seq(1,nrow(avg_dist_per_user),length.out = 10)]])
avg_dist_per_user = avg_dist_per_user[match(user_ids,avg_dist_per_user$user_id),]
avg_dist_per_user$user_id = factor(avg_dist_per_user$user_id, levels = user_ids)
o  = order(avg_dist_per_user$median_d)
o
user_ids =  as.character(avg_dist_per_user$user_id[o[seq(1,nrow(avg_dist_per_user),length.out = 10)]])
user_ids
seq(1,nrow(avg_dist_per_user),length.out = 10)
o[seq(1,nrow(avg_dist_per_user),length.out = 10)]
o[seq(1,nrow(avg_dist_per_user),length.out = 10)]
avg_dist_per_user
output_folder = paste0(IO$tmp_data,"avg_dist_per_user/")
dir.create(output_folder)
input_folder = paste0(IO$output_data,"days/")
days_files = list.files(input_folder)
days_files = days_files
N = length(days_files)
registerDoParallel(par$n_cores)
tic()
foreach(n = 1:N)%dopar%{
output_file = paste0(output_folder, "d_",n,".Rdata")
if(!file.exists(output_file)){
load(paste0(input_folder,days_files[n]), verbose = TRUE)
#impute and transform all cycles to wide format, including cycles without TB logs
user_ids = unique(days$user_id[days$type == "tender_breasts"])
days = days[days$user_id %in% user_ids,]
d = reshape_and_impute(days)
save(d, file = output_file)
}
}
toc()
stopImplicitCluster()
head(users)
table(users$batch)
users$batch
source("Scripts/00_functions_distance.R")
registerDoParallel(par$n_cores)
tic()
foreach(n = 1:N)%dopar%{
output_file = paste0(output_folder,"users_with_avg_distance_",n,".Rdata")
if(!file.exists(output_file)){
load(file = paste0(output_folder, "d_",n,".Rdata"), verbose = TRUE)
# compute average distance
users_with_avg_distance = foreach(u = unique(d$user_id), .combine = rbind) %do% {
dist_summary = compute_average_distance(d = d[d$user_id == u,])
return(data.frame(user_id = u, avg_d = dist_summary$mean, median_d = dist_summary$median, sd_d = dist_summary$sd, file = n))
}
save(users_with_avg_distance, file = output_file)
}
}
toc()
stopImplicitCluster()
registerDoParallel(par$n_cores)
tic()
avg_dist_per_user = foreach(n = 1:N,.combine = rbind)%dopar%{
load(file = paste0(output_folder,"users_with_avg_distance_",n,".Rdata"), verbose = TRUE)
return(users_with_avg_distance)
}
toc()
stopImplicitCluster()
save(avg_dist_per_user, file = paste0(IO$tmp_data,"avg_dist_per_user.Rdata"))
avg_dist_per_user
dim(avg_dist_per_user)
uniqueN(avg_dist_per_user$user_id)
load(file = paste0(output_folder, "d_1.Rdata"), verbose = TRUE)
load(paste0(IO$tmp_data,"avg_dist_per_user.Rdata"), verbose = TRUE)
uniqueN(avg_dist_per_user$user_id)
dim(avg_dist_per_user)
unique(d$user_id)
which(avg_dist_per_user$user_id %in% unique(d$user_id))
avg_dist_per_user = avg_dist_per_user[which(avg_dist_per_user$user_id %in% unique(d$user_id)),]
o  = order(avg_dist_per_user$median_d)
o
as.character(avg_dist_per_user$user_id[o[seq(1,nrow(avg_dist_per_user),length.out = min(nrow(avg_dist_per_user), 10))]])
user_ids =  as.character(avg_dist_per_user$user_id[o[seq(1,nrow(avg_dist_per_user),length.out = min(nrow(avg_dist_per_user), 10))]])
avg_dist_per_user = avg_dist_per_user[match(user_ids,avg_dist_per_user$user_id),]
avg_dist_per_user$user_id = factor(avg_dist_per_user$user_id, levels = user_ids)
d = melt(d)
d$cycleday_m_D = as.numeric(gsub("\\.","-",gsub("n\\.","",d$variable)))
d$cycle_nb_m = unlist(strsplit(as.character(d$cycle_id_m), "_"))[(1:nrow(d))*2]
d$tender_breasts = d$value
d = d[,c("user_id","cycle_nb_m","cycleday_m_D","tender_breasts")]
sel_d = d[d$user_id %in% user_ids ,]
sel_d$user_id = factor(sel_d$user_id, levels = user_ids)
g = ggplot_imputed_TB(sel_d = sel_d, facet_grid = "user_id", cycle_id = FALSE)
g
avg_dist_per_user
source("Scripts/00_setup.R")
load(paste0(IO$output_data, "users.Rdata"), verbose = TRUE)
load(paste0(IO$output_data,"cycles_m.Rdata"), verbose=  TRUE)
N = max(users$most_preval_clust, na.rm = TRUE)
N_users = 5
consistent_users = data.frame()
inconsistent_users = data.frame()
j = which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
n = 1
N
(users$most_preval_clust == n)
(users$most_preval_clust == n) &
(users$batch == 1)
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10)
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7)
which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
j = which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
sub_users = users[j,]
sub_users
o = order(sub_users$median_d, decreasing = FALSE)
sub_users[o[1],]
sub_users
n = 2
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7)
which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
j = which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
sub_users = users[j,]
o = order(sub_users$median_d, decreasing = FALSE)
sub_users[o[1],]
sub_users
N_users_n = min(N_users, floor(nrow(sub_users)/2))
N_users_n
N_users_n = min(N_users, ceiling(nrow(sub_users)/2))
N_users_n
for(n in 1:N){
j = which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
sub_users = users[j,]
o = order(sub_users$median_d, decreasing = FALSE)
sub_users[o[1],]
N_users_n = min(N_users, ceiling(nrow(sub_users)/2))
if(N_users_n >= 1){
consistent_users = rbind(consistent_users, sub_users[o[1:N_users_n],])
inconsistent_users = rbind(inconsistent_users, sub_users[o[(length(o)-N_users_n+1) : length(o)],])
}
}
consistent_users$consistent = TRUE
inconsistent_users$consistent = FALSE
selected_users = rbind(consistent_users, inconsistent_users)
selected_users
load(paste0(IO$tmp_data,"avg_dist_per_user/d_1.Rdata"), verbose = TRUE)
m = match(d$user_id, selected_users$user_id)
d$consistent = selected_users$consistent[m]
d$most_preval_cluster = selected_users$most_preval_clust[m]
d$cluster_num = cycles_m$cluster_num[match(d$cycle_id_m, cycles_m$cycle_id_m)]
sel_d = d[d$user_id %in% selected_users$user_id,]
sel_d = melt(sel_d, id.vars = c("user_id","cycle_id_m","consistent","most_preval_cluster","cluster_num"))
sel_d$cycleday_m_D = as.numeric(gsub("\\.","-",gsub("n\\.","",sel_d$variable)))
sel_d$cycle_nb_m = unlist(strsplit(as.character(sel_d$cycle_id_m), "_"))[(1:nrow(sel_d))*2]
sel_d$tender_breasts = sel_d$value
sel_d = sel_d[,c("user_id","cycle_nb_m","cycleday_m_D","tender_breasts","consistent","most_preval_cluster","cluster_num")]
sel_d_consistent = sel_d[sel_d$consistent, ]
sel_d_inconsistent = sel_d[!sel_d$consistent, ]
g_consistent = ggplot_imputed_TB(sel_d = sel_d_consistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
#scale_color_manual(values = cols$clusters_6)
g_inconsistent = ggplot_imputed_TB(sel_d = sel_d_inconsistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
g_consistent = ggplot_imputed_TB(sel_d = sel_d_consistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
#scale_color_manual(values = cols$clusters_6)
sel_d_inconsistent
load(paste0(IO$tmp_data,"avg_dist_per_user/d_1.Rdata"), verbose = TRUE)
m = match(d$user_id, selected_users$user_id)
d$consistent = selected_users$consistent[m]
d$most_preval_cluster = selected_users$most_preval_clust[m]
d$cluster_num = cycles_m$cluster_num[match(d$cycle_id_m, cycles_m$cycle_id_m)]
sel_d = d[d$user_id %in% selected_users$user_id,]
sel_d = melt(sel_d, id.vars = c("user_id","cycle_id_m","consistent","most_preval_cluster","cluster_num"))
sel_d$cycleday_m_D = as.numeric(gsub("\\.","-",gsub("n\\.","",sel_d$variable)))
sel_d$cycle_nb_m = unlist(strsplit(as.character(sel_d$cycle_id_m), "_"))[(1:nrow(sel_d))*2]
sel_d$tender_breasts = sel_d$value
sel_d = sel_d[,c("user_id","cycle_nb_m","cycleday_m_D","tender_breasts","consistent","most_preval_cluster","cluster_num")]
sel_d
table(sel_d$consistent)
selected_users
selected_users
m = match(d$user_id, selected_users$user_id)
m
N = max(users$most_preval_clust, na.rm = TRUE)
N_users = 5
consistent_users = data.frame()
inconsistent_users = data.frame()
for(n in 1:N){
j = which(
(users$most_preval_clust == n) &
(users$batch == 1) &
(users$n_cycles_m %in% 7:10) &
(users$perc_cycles_with_TB > 0.7))
sub_users = users[j,]
o = order(sub_users$median_d, decreasing = FALSE)
sub_users[o[1],]
N_users_n = min(N_users, ceiling(nrow(sub_users)/2))
if(N_users_n >= 1){
consistent_users = rbind(consistent_users, sub_users[o[1:N_users_n],])
inconsistent_users = rbind(inconsistent_users, sub_users[o[(length(o)-N_users_n+1) : length(o)],])
}
}
selected_users
consistent_users
inconsistent_users
load(paste0(IO$tmp_data,"avg_dist_per_user/d_1.Rdata"), verbose = TRUE)
m = match(d$user_id, selected_users$user_id)
d$consistent = selected_users$consistent[m]
d$most_preval_cluster = selected_users$most_preval_clust[m]
d$cluster_num = cycles_m$cluster_num[match(d$cycle_id_m, cycles_m$cycle_id_m)]
sel_d = d[d$user_id %in% selected_users$user_id,]
sel_d = melt(sel_d, id.vars = c("user_id","cycle_id_m","consistent","most_preval_cluster","cluster_num"))
sel_d$cycleday_m_D = as.numeric(gsub("\\.","-",gsub("n\\.","",sel_d$variable)))
sel_d$cycle_nb_m = unlist(strsplit(as.character(sel_d$cycle_id_m), "_"))[(1:nrow(sel_d))*2]
sel_d$tender_breasts = sel_d$value
sel_d = sel_d[,c("user_id","cycle_nb_m","cycleday_m_D","tender_breasts","consistent","most_preval_cluster","cluster_num")]
sel_d_consistent = sel_d[sel_d$consistent, ]
sel_d_inconsistent = sel_d[!sel_d$consistent, ]
if(nrow(sel_d_inconsistent)>0){
g_consistent = ggplot_imputed_TB(sel_d = sel_d_consistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
#scale_color_manual(values = cols$clusters_6)
g_inconsistent = ggplot_imputed_TB(sel_d = sel_d_inconsistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
#scale_color_manual(values = cols$clusters_6)
grid.arrange(g_consistent, g_inconsistent, nrow = 1)
}else{
g_consistent = ggplot_imputed_TB(sel_d = sel_d_consistent,
facet_grid = c("most_preval_cluster","user_id"), cycle_id = FALSE, col = "cluster_num")#+
#scale_color_manual(values = cols$clusters_6)
g_consistent
}
source("Scripts/00_setup.R")
load(paste0(IO$output_data, "users.Rdata"), verbose = TRUE)
load(paste0(IO$output_data,"cycles_m.Rdata"), verbose=  TRUE)
agg = aggregate(n_TB ~ user_id, cycles_m, sum)
users$n_TB = agg$n_TB[match(users$user_id, agg$user_id)]
# selecting users that have only 1 transition and that have ever tracked TB
user_ids = users$user_id[
(users$BC %in% c("on pill","off pill","off-on pill","on-off pill")) &
(users$n_TB >= 2)]
# selecting users that have a least 4 cycles of each BC
users_sub = users[users$user_id %in% user_ids, c("user_id","n_cycles_m","BC")]
users_exp = as.data.frame(lapply(users_sub, rep, users_sub$n_cycles_m))
colnames(users_exp)[colnames(users_exp)== "BC"] = "user_BC"
users_exp$cycle_nb_m = ave(rep(1,nrow(users_exp)), users_exp$user_id, FUN =cumsum)
users_exp$cycle_id_m = paste0(users_exp$user_id, "_",users_exp$cycle_nb_m)
agg = aggregate(n_TB ~ user_id, cycles_m, sum)
users$n_TB = agg$n_TB[match(users$user_id, agg$user_id)]
# selecting users that have only 1 transition and that have ever tracked TB
user_ids = users$user_id[
(users$BC %in% c("on pill","off pill","off-on pill","on-off pill")) &
(users$n_TB >= 2)]
user_ids
users_sub = users[users$user_id %in% user_ids, c("user_id","n_cycles_m","BC")]
users_exp = as.data.frame(lapply(users_sub, rep, users_sub$n_cycles_m))
colnames(users_exp)[colnames(users_exp)== "BC"] = "user_BC"
users_exp$cycle_nb_m = ave(rep(1,nrow(users_exp)), users_exp$user_id, FUN =cumsum)
users_exp$cycle_id_m = paste0(users_exp$user_id, "_",users_exp$cycle_nb_m)
users_exp$cycle_nb_m = ave(rep(1,nrow(users_exp)), users_exp$user_id, FUN =cumsum)
users_exp$cycle_id_m = paste0(users_exp$user_id, "_",users_exp$cycle_nb_m)
length(user_ids)>0
source("Scripts/00_setup.R")
load(file = paste0(IO$output_data,"users.Rdata"), verbose = TRUE)
load(file = paste0(IO$tmp_data, "days_pill_trans.Rdata"), verbose = TRUE)
days_pill_trans_file = paste0(IO$tmp_data, "days_pill_trans.Rdata")
file.exists(days_pill_trans_file)
par$n_cores = detectCores() - 1
days_output = paste0(IO$output_data,"days/")
iris
write.csv(iris, file = "/Users/laurasymul/Desktop/iris.csv", quote = FALSE, append = TRUE, row.names = FALSE, col.names = FALSE)
?write.csv
colnames(iris)
write.table(iris, file = "/Users/laurasymul/Desktop/iris.csv", quote = FALSE, append = TRUE,sep = ",", row.names = FALSE, col.names = FALSE)
write.table(iris, file = "/Users/laurasymul/Desktop/iris.csv", quote = FALSE, append = TRUE,sep = ",", row.names = FALSE, col.names = FALSE)
?read.csv
?install.packages("sqldf")
install.packages("sqldf")
library(EV)
library(sqldf)
install.packages("tcltk")
capabilities("tcltk")
library(tcltk)
install.packages("tcltk2")
library(tcltk)
library(microbenchmark)
install.packages("microbenchmark")
data_frame(
norm = rnorm(5e6, mean = 5000, sd = 1000),
unif = runif(5e6, min = 0, max = 10000)
) %>%
write_csv('medium.csv')
microbenchmark(
readr  = read_csv_chunked('medium.csv', callback = DataFrameCallback$new(function(x, pos) subset(x, unif > 9000)), col_types = 'dd', progress = F),
readr2 = read_csv_chunked('medium.csv', callback = DataFrameCallback$new(function(x, pos) subset(x, unif > 9000)), col_types = 'dd', progress = F, chunk_size = 1000000),
sqldf  = read.csv.sql('medium.csv', sql = 'select * from file where unif > 9000', eol = '\n'),
awk    = read.csv(pipe("awk 'BEGIN {FS=\",\"} {if ($2 > 9000) print $0}' medium.csv")),
awk2   = read_csv(pipe("awk 'BEGIN {FS=\",\"} {if ($2 > 9000) print $0}' medium.csv"), col_types = 'dd', progress = F),
check  = function(values) all(sapply(values[-1], function(x) all.equal(values[[1]], x))),
times  = 10L
)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(sqldf)
library(microbenchmark)
# Generate an example dataset with two numeric columns and 5 million rows
data_frame(
norm = rnorm(5e6, mean = 5000, sd = 1000),
unif = runif(5e6, min = 0, max = 10000)
) %>%
write_csv('medium.csv')
microbenchmark(
readr  = read_csv_chunked('medium.csv', callback = DataFrameCallback$new(function(x, pos) subset(x, unif > 9000)), col_types = 'dd', progress = F),
readr2 = read_csv_chunked('medium.csv', callback = DataFrameCallback$new(function(x, pos) subset(x, unif > 9000)), col_types = 'dd', progress = F, chunk_size = 1000000),
sqldf  = read.csv.sql('medium.csv', sql = 'select * from file where unif > 9000', eol = '\n'),
awk    = read.csv(pipe("awk 'BEGIN {FS=\",\"} {if ($2 > 9000) print $0}' medium.csv")),
awk2   = read_csv(pipe("awk 'BEGIN {FS=\",\"} {if ($2 > 9000) print $0}' medium.csv"), col_types = 'dd', progress = F),
check  = function(values) all(sapply(values[-1], function(x) all.equal(values[[1]], x))),
times  = 10L
)
install.packages("tidyverse")
library(tidyverse)
install.packages("~/Downloads/tidyverse_1.2.1.tgz", repos = NULL, type = .Platform$pkgType)
library(tidyverse)
R.version
?as.data.frame
source("Scripts/00_setup.R")
